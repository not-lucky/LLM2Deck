# Product Description: LLM2Deck

## Overview
LLM2Deck is an advanced, automated system designed to revolutionize how Anki flashcards are created. By employing a multi-model "Mixture of Agents" approach, it generates high-quality, comprehensive study materials that far exceed the capabilities of a single LLM. The system treats Large Language Models not as single sources of truth, but as collaborative generators whose outputs are synthesized, refined, and formatted into perfect Anki decks.

## Core Architectural Constraint
**Generic OpenAI-Compatible Provider Interface**:
To ensure maximum flexibility and complete vendor independence, the system is architected around a **single, generic OpenAI-compatible API client**.
- **Universal Compatibility**: The system works with *any* provider that adheres to the OpenAI chat completion API standard (e.g., Cerebras, OpenRouter, Canopywave, DeepSeek, local vLLM instances).
- **Configuration-Driven**: Adding a new AI provider requires **zero code changes**. Users simply add an entry to `config.yaml` with the provider's `base_url`, `api_key` (or path to key file), and model name.
- **Uniform Handling**: The system applies the same retry logic, rate limiting, and error handling to all providers uniformly.

## Detailed Feature Specification

### 1. Advanced Generation Pipeline
The core of LLM2Deck is its three-stage pipeline designed to maximize quality and minimize hallucinations.

#### Stage A: Parallel Generation (The "Committee")
Instead of relying on one model, the system queries multiple configured providers simultaneously for the same topic.
- **Diversity of Thought**: Different models (e.g., Llama 3.3 vs. Qwen 2.5 vs. GPT-4o) have different strengths. Some are better at code, others at conceptual explanations. Parallel generation captures the best of all worlds.
- **Concurrency Control**: A configurable semaphore limits the number of active requests to prevent rate-limiting and manage system resources.
- **Robust Error Handling**: If one provider fails (timeout, 500 error), it doesn't crash the pipeline. The system logs the failure and proceeds with the successful responses from other providers.

#### Stage B: Intelligent Synthesis (The "Combiner")
A designated high-reasoning model acts as the editor-in-chief.
- **Deduplication**: Identifies and merges overlapping cards generated by different providers.
- **Conflict Resolution**: If providers disagree (e.g., on a specific fact or code implementation), the combiner resolves the discrepancy to ensure accuracy.
- **Quality Filtering**: Discards low-quality, vague, or irrelevant cards.
- **Prompt Chaining**: The combiner receives a specialized system prompt that instructs it to act as an expert curator, taking raw JSON inputs and producing a refined list.

#### Stage C: Schema Enforcement (The "Formatter")
An optional but critical stage for ensuring machine-readable output.
- **JSON Repair**: Some reasoning models are great at content but bad at strict JSON syntax. The formatter takes the combiner's text and forces it into the strict JSON schema required by the Anki generator.
- **Validation**: Ensures all required fields (front, back, tags) are present and correctly typed.

### 2. Flexible Input & Ingestion
The system supports multiple ways to define *what* to study.

- **Subject-Based Mode**:
    - Uses pre-defined "subjects" (like LeetCode, Physics) defined in configuration.
    - Each subject can have its own custom prompt templates (`initial.md`, `combine.md`).
    - Supports retrieving questions from a central `questions.json` database.
- **Document Ingestion Mode**:
    - Recursively scans a local directory for source files (`.md`, `.txt`, `.html`, `.pdf`).
    - **Structural Mapping**: Mirrors the file system structure into the Anki deck structure (e.g., a folder named "Biology/Cell Structure" becomes a subdeck `Biology::Cell Structure`).
    - **Chunking**: Automatically splits large documents into manageable chunks for LLM processing.

### 3. Rich Output Generation
The system doesn't just output text; it creates full-featured Anki packages.

- **Anki Package (.apkg)**:
    - Native binary export ready for one-click import into Anki.
    - **Markdown Rendering**: Compiles Markdown (bold, italics, lists, tables) into HTML for card display.
    - **Syntax Highlighting**: Code blocks are rendered with syntax highlighting for better readability.
- **Metadata & Tagging**:
    - **Hierarchical Tags**: Cards are automatically tagged with their source path (e.g., `tag:physics::mechanics`).
    - **Smart Card Types**: Supports "Basic" (Front/Back) and "MCQ" (Multiple Choice) card types, with automatic shuffling of options for MCQs.
- **Archival Formats**:
    - Saves raw JSON outputs for auditing, debugging, or re-generation without re-incurring API costs.
    - Exports to Markdown for human-readable review of generated content.

### 4. Operational Reliability & Cost Management
Built for long-running batch jobs that process hundreds of topics.

- **Granular Resumability**:
    - The system tracks progress at the *question* level in a SQLite database.
    - If a run crashes after 50 out of 100 questions, restarting it will seamlessly resume at question 51.
- **Response Caching**:
    - Implements a content-addressable cache (hashing the prompt + model parameters).
    - Prevents paying for the exact same generation twice.
- **Budgeting System**:
    - **Pre-Flight Estimation**: analyzing the input queue and provider pricing to estimate total run cost before starting.
    - **Hard Budget Limit**: Users can set a flag `--budget 5.0` (USD). The system tracks cumulative usage and stops execution before the budget is exceeded.

### 5. Comprehensive CLI & Querying
A suite of tools to manage the lifecycle of deck generation.

- **`generate`**: The main driver for topic-based generation. Supports dry-runs, specific question filtering (`--question "Two Sum"`), and card type selection.
- **`ingest`**: The driver for document-based generation.
- **`query`**: A powerful SQL-backed introspection tool.
    - `query runs`: See history of all generation sessions.
    - `query cards`: Search through generated cards text.
    - `query stats`: View success rates, token usage, and provider performance metrics.
- **`cache`**: Tools to inspect cache hit rates or clear old cache entries.
