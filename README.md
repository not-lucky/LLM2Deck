# LLM2Deck

<p align="center">
  <strong>Generate high-quality Anki flashcards using multiple LLMs in parallel</strong>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#installation">Installation</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#configuration">Configuration</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#development">Development</a>
</p>

---

LLM2Deck is a powerful tool that generates comprehensive Anki flashcard decks by orchestrating multiple Large Language Models in parallel. It uses a two-stage generation process: first, multiple LLMs generate cards independently, then a "combiner" model synthesizes the best elements into a final, polished deck.

## Features

- **Parallel LLM Generation** â€” Query multiple providers simultaneously (Cerebras, OpenRouter, NVIDIA NIM, Google Gemini, and more)
- **Two-Stage Quality Pipeline** â€” Generate â†’ Combine workflow produces higher-quality cards than single-model approaches
- **Real-Time Progress Visualization** â€” Rich progress bar with ETA, provider status indicators, and live token/cost tracking
- **Cost Estimation & Budgeting** â€” Pre-run cost estimates, budget limits, and cumulative cost tracking across runs
- **Built-in Subjects** â€” LeetCode algorithms, Computer Science fundamentals, and Physics concepts ready to go
- **Custom Subjects** â€” Define your own subjects with custom prompts and question sets
- **Multiple Card Formats** â€” Standard Q&A and Multiple Choice Question (MCQ) modes
- **Beautiful Cards** â€” Catppuccin-themed styling with syntax highlighting for code
- **Full Traceability** â€” SQLite database tracks all runs, provider outputs, and final cards
- **Caching** â€” Intelligent response caching to avoid redundant API calls
- **Anki Export** â€” Direct conversion to `.apkg` format ready for import

## Installation

### Prerequisites

- **Python 3.12+**
- **[uv](https://github.com/astral-sh/uv)** package manager (recommended)

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/LLM2Deck.git
cd LLM2Deck

# Install dependencies with uv
uv sync

# Or with pip
pip install -e .
```

### API Keys

Create JSON files at the project root for each provider you want to use:

| Provider | Key File | Format |
|----------|----------|--------|
| Cerebras | `api_keys.json` | `{"keys": ["key1", "key2"]}` |
| OpenRouter | `openrouter_apikeys.json` | `{"keys": ["key1"]}` |
| NVIDIA NIM | `nvidia_keys.json` | `{"keys": ["key1"]}` |
| Google GenAI | `google_genai_keys.json` | `{"keys": ["key1"]}` |
| Canopywave | `canopywave_keys.json` | `{"keys": ["key1"]}` |
| Baseten | `baseten_keys.json` | `{"keys": ["key1"]}` |

You can also set key file paths via environment variables:
- `CEREBRAS_KEYS_FILE_PATH`
- `OPENROUTER_KEYS_FILE_PATH`
- `NVIDIA_KEYS_FILE_PATH`
- `GOOGLE_GENAI_KEYS_FILE_PATH`

## Quick Start

```bash
# Generate LeetCode flashcards (default)
uv run main.py generate

# Generate CS concept cards in MCQ format
uv run main.py generate cs mcq

# Convert generated JSON to Anki package
uv run main.py convert leetcode_anki_deck_20260109T154055.json

# Import the .apkg file into Anki!
```

## Usage

### Commands Overview

```bash
uv run main.py <command> [options]

Commands:
  generate    Generate flashcards from LLM providers
  convert     Convert JSON deck to Anki .apkg format
  merge       Merge archived JSON files for a subject
  export-md   Export JSON cards to Markdown format
  cache       Cache management (clear, stats)
  query       Query database for runs, problems, cards, and statistics
```

### Generate Cards

```bash
# Basic usage
uv run main.py generate                          # LeetCode standard (default)
uv run main.py generate <subject>                # Specific subject
uv run main.py generate <subject> mcq            # MCQ format
uv run main.py generate cs mcq --label "test"    # With run label

# Built-in subjects: leetcode, cs, physics
# Custom subjects: defined in config.yaml

# Options
--label TEXT       Optional label for this run (stored in database)
--dry-run          Show what would be done without making API calls
--no-cache         Bypass cache lookup (still stores new results)
--resume RUN_ID    Resume a failed/interrupted run (skips already-processed questions)
--budget AMOUNT    Maximum budget in USD (stops generation when exceeded)
--estimate-only    Show cost estimate without generating cards

# Question Filters (selective generation)
--category TEXT    Only generate for specific category (partial match)
--question TEXT    Only generate for matching questions (partial match)
--limit N          Maximum number of questions to process
--skip-until TEXT  Skip questions until reaching this one
```

**Examples:**

```bash
# Generate LeetCode algorithm cards
uv run main.py generate leetcode

# Generate Computer Science MCQs with a label
uv run main.py generate cs mcq --label "exam-prep"

# Preview generation without API calls
uv run main.py generate physics --dry-run

# Resume a failed run (use partial run ID from query runs)
uv run main.py generate leetcode --resume abc12345

# Generate only from "Arrays and Hashing" category
uv run main.py generate leetcode --category "Arrays"

# Generate only questions matching "Binary Search"
uv run main.py generate cs --question "Binary Search"

# Quick test with only 3 questions
uv run main.py generate leetcode --limit 3

# Start from a specific question
uv run main.py generate physics --skip-until "Quantum Mechanics"

# Combine filters: Trees category, first 5 questions
uv run main.py generate leetcode --category "Trees" --limit 5
```

### Resume Failed Runs

If a generation run crashes or fails mid-way, you can resume it to avoid reprocessing already-completed questions:

```bash
# 1. Find the failed run ID
uv run main.py query runs --status failed

# 2. Resume the run (supports partial IDs)
uv run main.py generate leetcode --resume abc12345
```

The resume feature:
- **Skips processed questions** â€” Questions that succeeded in the original run are not regenerated
- **Merges results** â€” Combines existing results with newly generated ones in the final output
- **Updates run status** â€” The run is marked as completed once all questions are processed
- **Preserves run ID** â€” Uses the same run ID for traceability

**Validation:**
- The run must exist and have status "failed" or "running" (not "completed")
- The subject and card type must match the original run
- Partial run IDs work (e.g., first 8 characters)

### Progress Visualization

During generation, LLM2Deck displays a real-time progress panel:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM2Deck Generation Progress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ â— Generating cards â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 35% (7/20) 0:02:15 â”‚
â”‚                                                                        â”‚
â”‚ Current: Binary Search Tree Insertion                                  â”‚
â”‚                                                                        â”‚
â”‚               Provider Status                                          â”‚
â”‚ Provider          Model              Status  Success Failed Tokens Costâ”‚
â”‚ cerebras          llama-70b          âœ“ success    7      0   45,230 $0.02â”‚
â”‚ google_antigravity gemini-pro        âœ“ success    7      0   52,100 $0.00â”‚
â”‚ nvidia            kimi-k2-thinking   ğŸ”„ running   6      1   38,500 $0.02â”‚
â”‚                                                                        â”‚
â”‚ ETA: 4.2m â”‚ Total Tokens: 135,830 â”‚ Est. Cost: $0.0412                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

Features:
- **Progress bar** with question count and elapsed time
- **Current question** being processed
- **Provider status table** showing success/fail counts, tokens used, and estimated cost
- **ETA estimation** based on rolling average of processing times
- **Live cost tracking** per provider with automatic pricing lookup

### Cost Estimation & Budgeting

LLM2Deck provides visibility into API costs before, during, and after generation:

```bash
# Pre-run cost estimation without generating
uv run main.py generate leetcode --estimate-only

# Set a budget limit (stops when exceeded)
uv run main.py generate leetcode --budget 1.00

# View cost for a completed run
uv run main.py query run abc12345

# View cumulative costs across all runs
uv run main.py query stats
```

**Example cost estimate output:**
```
============================================================
COST ESTIMATE
============================================================
Questions to process: 50
Estimated tokens: 100,000 in / 75,000 out
Estimated total cost: $0.1050

Per provider:
  cerebras/gpt-oss-120b: $0.0420
  google_genai/gemini-2.0-flash: $0.0175
  google_antigravity/gemini-3-pro: $0.0000
============================================================
```

**Budget enforcement:**
- Use `--budget <amount>` to set a maximum spend in USD
- LLM2Deck checks the budget before starting each question
- If continuing would exceed the budget, generation stops gracefully
- Already-processed questions are saved; use `--resume` to continue later

**Cost tracking in database:**
- Each run stores: total input/output tokens, estimated cost, budget limit (if set)
- Query with `uv run main.py query stats` to see cumulative costs
- Run details include full cost breakdown

### Convert to Anki

```bash
uv run main.py convert <json_file> [options]

Options:
  --mode MODE      Override auto-detected mode (leetcode, cs, physics, *_mcq)
  --output FILE    Custom output filename
  --dry-run        Preview without writing files
```

**Examples:**

```bash
# Auto-detect mode from filename
uv run main.py convert leetcode_anki_deck_20260109T154055.json

# Specify output file
uv run main.py convert cs_cards.json --output my_cs_deck.apkg

# Force MCQ mode
uv run main.py convert cards.json --mode cs_mcq
```

### Merge Archives

Combine multiple JSON files from different runs into a single deck:

```bash
uv run main.py merge <subject>

# Preview merge operation
uv run main.py merge leetcode --dry-run
```

### Export to Markdown

Convert archived JSON cards to readable Markdown format:

```bash
uv run main.py export-md [options]

Options:
  --source DIR    Source directory with JSON files
  --target DIR    Target directory for Markdown output
  --dry-run       Preview without writing files
```

### Cache Management

```bash
# View cache statistics
uv run main.py cache stats

# Clear all cached responses
uv run main.py cache clear
```

### Query Database

Inspect runs, problems, provider results, and cards in the database:

```bash
# List recent runs
uv run main.py query runs
uv run main.py query runs --subject leetcode --status completed --limit 10

# Show details for a specific run (supports partial ID)
uv run main.py query run abc12345

# List problems
uv run main.py query problems --run abc12345
uv run main.py query problems --status success --search "binary"

# List provider results
uv run main.py query providers --run abc12345 --success
uv run main.py query providers --provider cerebras

# Search cards
uv run main.py query cards --search "binary search"
uv run main.py query cards --type Algorithm --limit 20

# Show global statistics
uv run main.py query stats
uv run main.py query stats --subject leetcode

# Output formats
uv run main.py query runs --format json      # JSON output
uv run main.py query runs --format table     # Table output (default)
```

## Configuration

### config.yaml

The main configuration file controls all aspects of LLM2Deck:

```yaml
# Global defaults for all providers
defaults:
  timeout: 120.0              # Request timeout in seconds
  temperature: 0.4            # Sampling temperature
  max_tokens: null            # Max tokens (null = API default)
  max_retries: 5              # Retry attempts for API requests
  json_parse_retries: 5       # Retries for JSON parsing
  retry_delay: 1.0            # Base delay between retries

# Provider Configuration
providers:
  cerebras:
    enabled: true
    model: "gpt-oss-120b"
    reasoning_effort: "high"

  openrouter:
    enabled: false
    model: "xiaomi/mimo-v2-flash:free"

  nvidia:
    enabled: false
    model: "moonshotai/kimi-k2-thinking"
    timeout: 900
    max_tokens: 16384

  google_genai:
    enabled: false
    model: "gemini-3-flash-preview"
    thinking_level: "high"
    temperature: 1.0

  google_antigravity:
    enabled: true
    models:
      - "gemini-3-pro-preview"
      - "gemini-claude-opus-4-5-thinking"
    timeout: 900

# Generation Settings
generation:
  concurrent_requests: 7      # Max parallel API requests
  request_delay: 1            # Delay between starting requests
  max_retries: 10

  # Combiner merges outputs from all generators
  combiner:
    provider: google_antigravity
    model: gemini-claude-opus-4-5-thinking
    also_generate: true       # Also use as generator

  # Optional formatter for JSON output
  formatter:
    provider: cerebras
    model: gpt-oss-120b
    also_generate: false

# Subject Settings
subjects:
  leetcode:
    enabled: true
  cs:
    enabled: true
  physics:
    enabled: false

  # Custom subject example
  # my_subject:
  #   enabled: true
  #   deck_prefix: "MySubject"
  #   prompts_dir: "prompts/my_subject"
  #   questions_file: "data/my_questions.json"

# Paths
paths:
  archival_dir: "anki_cards_archival"
  markdown_dir: "anki_cards_markdown"
  timestamp_format: "%Y%m%dT%H%M%S"

# Database
database:
  path: "llm2deck.db"
```

### Provider Configuration

Each provider supports these common options:

| Option | Description | Default |
|--------|-------------|---------|
| `enabled` | Whether to use this provider | `false` |
| `model` | Model identifier | Provider-specific |
| `timeout` | Request timeout (seconds) | `120.0` |
| `temperature` | Sampling temperature | `0.4` |
| `max_tokens` | Maximum output tokens | API default |
| `max_retries` | Retry attempts | `5` |

Provider-specific options:
- **Cerebras**: `reasoning_effort` (low/medium/high)
- **Google GenAI**: `thinking_level` (low/medium/high)
- **G4F**: `provider_name` (LMArena, etc.)

### Adding Custom Subjects

1. **Create prompt templates:**

```bash
mkdir -p prompts/my_subject
```

Create `prompts/my_subject/initial.md`:
```markdown
You are an expert tutor on {question}.

Generate comprehensive Anki cards covering:
- Key concepts
- Examples
- Common misconceptions

Output valid JSON matching the schema.
```

Create `prompts/my_subject/combine.md`:
```markdown
You are synthesizing multiple card sets for {question}.

Combine the best elements from each set:
{combined_inputs}

Output a unified set of high-quality cards as valid JSON.
```

2. **Create questions file:**

Create `data/my_questions.json`:
```json
{
  "Category 1": [
    "Question 1",
    "Question 2"
  ],
  "Category 2": [
    "Question 3"
  ]
}
```

3. **Add to config.yaml:**

```yaml
subjects:
  my_subject:
    enabled: true
    deck_prefix: "MySubject"
    prompts_dir: "prompts/my_subject"
    questions_file: "data/my_questions.json"
```

4. **Generate cards:**

```bash
uv run main.py generate my_subject
```

## Architecture

### Generation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Orchestrator                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚ Provider â”‚  â”‚ Provider â”‚  â”‚ Provider â”‚   â† Parallel Generation  â”‚
â”‚   â”‚ Cerebras â”‚  â”‚  NVIDIA  â”‚  â”‚  Gemini  â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚        â”‚             â”‚             â”‚                                 â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                      â”‚                                               â”‚
â”‚                      â–¼                                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚              â”‚   Combiner   â”‚  â† Synthesize best cards               â”‚
â”‚              â”‚   (Gemini)   â”‚                                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                     â”‚                                                â”‚
â”‚                     â–¼                                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚              â”‚  Formatter   â”‚  â† Optional JSON formatting            â”‚
â”‚              â”‚  (Cerebras)  â”‚                                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                     â”‚                                                â”‚
â”‚                     â–¼                                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚              â”‚  Final JSON  â”‚                                        â”‚
â”‚              â”‚   + SQLite   â”‚                                        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
LLM2Deck/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ config.yaml             # Runtime configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.py              # CLI interface (argparse)
â”‚   â”œâ”€â”€ orchestrator.py     # Generation workflow coordinator
â”‚   â”œâ”€â”€ generator.py        # Parallel card generation
â”‚   â”œâ”€â”€ progress.py         # Real-time progress visualization
â”‚   â”œâ”€â”€ prompts.py          # PromptLoader - lazy prompt loading
â”‚   â”œâ”€â”€ models.py           # Pydantic models (LeetCodeProblem, etc.)
â”‚   â”œâ”€â”€ database.py         # SQLite operations
â”‚   â”œâ”€â”€ repositories.py     # Database abstraction layer
â”‚   â”œâ”€â”€ exceptions.py       # Custom exceptions
â”‚   â”œâ”€â”€ task_runner.py      # Concurrent task execution
â”‚   â”œâ”€â”€ cache.py            # Response caching
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ loader.py       # YAML config parsing
â”‚   â”‚   â”œâ”€â”€ subjects.py     # SubjectRegistry
â”‚   â”‚   â”œâ”€â”€ keys.py         # API key loading
â”‚   â”‚   â”œâ”€â”€ models.py       # Config dataclasses
â”‚   â”‚   â””â”€â”€ modes.py        # Mode definitions
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.py         # LLMProvider abstract base
â”‚   â”‚   â”œâ”€â”€ openai_compatible.py  # Shared implementation
â”‚   â”‚   â”œâ”€â”€ registry.py     # Provider factory
â”‚   â”‚   â”œâ”€â”€ cerebras.py     # Cerebras provider
â”‚   â”‚   â”œâ”€â”€ nvidia.py       # NVIDIA NIM
â”‚   â”‚   â”œâ”€â”€ openrouter.py   # OpenRouter
â”‚   â”‚   â”œâ”€â”€ google_genai.py # Google Generative AI
â”‚   â”‚   â””â”€â”€ ...             # Other providers
â”‚   â”œâ”€â”€ anki/
â”‚   â”‚   â”œâ”€â”€ generator.py    # DeckGenerator
â”‚   â”‚   â”œâ”€â”€ models.py       # Anki note models
â”‚   â”‚   â”œâ”€â”€ renderer.py     # Markdown â†’ HTML
â”‚   â”‚   â””â”€â”€ styles.py       # Catppuccin theme CSS
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ merge.py        # MergeService
â”‚   â”‚   â””â”€â”€ export.py       # ExportService
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ prompts/        # Prompt templates
â”‚       â””â”€â”€ questions.json  # Built-in questions
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ anki_cards_archival/    # Archived JSON outputs
â””â”€â”€ llm2deck.db             # SQLite database
```

### Card Models

**Standard Cards (Q&A):**
```json
{
  "title": "Two Sum",
  "topic": "Arrays and Hashing",
  "difficulty": "Easy",
  "cards": [
    {
      "card_type": "Concept",
      "tags": ["Arrays", "HashMap"],
      "front": "What is the Two Sum problem?",
      "back": "Given an array and target, find two numbers that sum to target..."
    }
  ]
}
```

**MCQ Cards:**
```json
{
  "title": "Binary Trees",
  "topic": "Data Structures",
  "difficulty": "Medium",
  "cards": [
    {
      "card_type": "Application",
      "tags": ["Trees", "Traversal"],
      "question": "What is the time complexity of BFS on a tree?",
      "options": ["A. O(1)", "B. O(log n)", "C. O(n)", "D. O(nÂ²)"],
      "correct_answer": "C",
      "explanation": "BFS visits each node exactly once..."
    }
  ]
}
```

### Database Schema

LLM2Deck tracks all generation data in SQLite:

| Table | Purpose |
|-------|---------|
| `runs` | Execution metadata, timestamps, statistics |
| `problems` | Individual questions processed |
| `provider_results` | Raw LLM outputs before combination |
| `cards` | Final individual cards |
| `cache` | Cached LLM responses |

## Card Styling

Cards are styled with the **Catppuccin** color scheme, automatically adapting to Anki's light/dark mode:

- **Latte** (light) â€” Clean, readable daytime theme
- **Mocha** (dark) â€” Easy on the eyes for night study

Features:
- Syntax highlighting for code blocks (Pygments)
- Responsive typography
- Clear visual hierarchy for card types, tags, and metadata

## Development

### Setup Development Environment

```bash
# Install with dev dependencies
uv sync --dev

# Or with pip
pip install -e ".[dev]"
```

### Running Tests

```bash
# All tests (LLM calls are mocked)
uv run pytest

# By category
uv run pytest tests/unit/ -m unit          # Fast, isolated
uv run pytest tests/integration/           # Component interactions
uv run pytest tests/e2e/                   # Full CLI workflows

# Parallel execution
uv run pytest tests/unit/ -n auto

# With coverage
uv run pytest --cov=src --cov-report=html

# Random order (verify isolation)
uv run pytest --random-order

# Check test metrics
uv run python scripts/test-metrics.py
```

### Type Checking

```bash
# Uses 'ty' type checker
ty check src/
```

### Code Quality Targets

- **Test-to-code ratio**: 5:1 for core modules, 2:1 for peripheral
- **Coverage**: 87%+ overall
- **Test count**: 1500+ tests

### Adding a New Provider

1. **Create provider class:**

```python
# src/providers/my_provider.py
from src.providers.openai_compatible import OpenAICompatibleProvider

class MyProvider(OpenAICompatibleProvider):
    def __init__(self, api_keys: Iterator[str], model: str):
        super().__init__(
            model=model,
            base_url="https://api.example.com/v1",
            api_keys=api_keys,
        )

    @property
    def name(self) -> str:
        return "my_provider"
```

2. **Register in `src/providers/registry.py`**

3. **Add key config in `src/config/keys.py`**

4. **Add to `config.yaml`**

### Project Guidelines

- **Error Handling**: Use custom exceptions from `src/exceptions.py`
- **Async Pattern**: Use `asyncio` for all I/O operations
- **Testing**: Mock all LLM calls, never make real API requests in tests
- **Configuration**: All settings via `config.yaml`, environment variables for secrets

## Troubleshooting

### Common Issues

**"No providers enabled"**
- Check `config.yaml` â€” at least one provider must have `enabled: true`
- Verify API key files exist and contain valid keys

**"All providers failed"**
- Check API key validity
- Verify network connectivity
- Review `app.log` for detailed error messages

**"JSON parse error"**
- Some models produce invalid JSON â€” configure a `formatter` provider
- Increase `json_parse_retries` in config

**Rate limiting**
- Increase `request_delay` in generation settings
- Reduce `concurrent_requests`

### Logs

Check `app.log` for detailed execution logs:

```bash
tail -f app.log
```

### Database Queries

Use the built-in query command for easy database inspection:

```bash
# List recent runs with statistics
uv run main.py query runs --limit 5

# Show detailed run statistics
uv run main.py query run <run_id>

# Search cards
uv run main.py query cards --search "binary search"

# Global statistics
uv run main.py query stats
```

Or inspect the SQLite database directly:

```bash
sqlite3 llm2deck.db

# Recent runs
SELECT * FROM runs ORDER BY created_at DESC LIMIT 5;

# Provider success rates
SELECT provider_name, COUNT(*) FROM provider_results GROUP BY provider_name;
```

## Built-in Subjects

### LeetCode (`leetcode`)

Covers NeetCode 150 patterns:
- Arrays and Hashing
- Two Pointers
- Sliding Window
- Stacks
- Binary Search
- Linked Lists
- Trees
- Tries
- Heap/Priority Queue
- Backtracking
- Graphs
- Dynamic Programming
- And more...

Cards include:
- Problem understanding
- Multiple solution approaches (brute force â†’ optimal)
- Code implementations (Python)
- Complexity analysis
- Common pitfalls

### Computer Science (`cs`)

Foundational CS concepts:
- Python fundamentals
- Data structures (stacks, queues, trees, graphs)
- Algorithms (sorting, searching)
- Recursion and dynamic programming
- System design basics

### Physics (`physics`)

Core physics topics:
- Mechanics
- Thermodynamics
- Electromagnetism
- Waves and optics
- Modern physics

## License

MIT License â€” see [LICENSE](LICENSE) for details.

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Write tests for new functionality
4. Ensure all tests pass (`uv run pytest`)
5. Submit a pull request

See [TESTING.md](TESTING.md) for testing guidelines and [AGENTS.md](AGENTS.md) for detailed development documentation.

---

<p align="center">
  Made with â¤ï¸ for spaced repetition learners
</p>
